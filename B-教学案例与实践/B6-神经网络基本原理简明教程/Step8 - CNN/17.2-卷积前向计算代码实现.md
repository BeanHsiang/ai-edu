Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可

## 17.2 卷积前向计算代码实现

### 17.2.1 卷积核的实现

卷积核，实际上和全连接层一样，是权重矩阵加偏移向量的组合。

```Python
class ConvWeightsBias(WeightsBias_2_1):
    def __init__(self, output_c, input_c, filter_h, filter_w, init_method, optimizer_name, eta):
        self.FilterCount = output_c
        self.KernalCount = input_c
        self.KernalHeight = filter_h
        self.KernalWidth = filter_w
        ...

    def Initialize(self, folder, name, create_new):
        self.WBShape = (self.FilterCount, self.KernalCount, self.KernalHeight, self.KernalWidth)        
        ...

    def CreateNew(self):
        self.W = ConvWeightsBias.InitialConvParameters(self.WBShape, self.init_method)
        self.B = np.zeros((self.FilterCount, 1))
...
```
<img src="../Images/17/ConvWeightsBias.png">

以上图为例，各个维度的数值如下：

- FilterCount=2，过滤器数量，对应输出通道数。
- KernalCount=3，卷积核数量，对应输入通道数。两个Filter里面的Kernal数必须相同。
- KernalHeight=5，KernalWidth=5，卷积核的尺寸。同一组WeightsBias里的卷积核尺寸必须相同。

在初始化函数中，会根据四个参数定义WBShape，然后在CreateNew函数中，创建相应形状的Weights和Bias。

### 17.2.2 卷积运算的实现 - 方法1

所谓动态方法，就是用标准的Python来实现卷积运算。

如果有必要的话，先对输入矩阵做padding，然后做四维卷积运算。

```Python
    if self.padding > 0:
        self.padded = np.pad(self.x, ((0,0), (0,0), (self.padding,self.padding), (self.padding,self.padding)), 'constant')
    else:
        self.padded = self.x
```

下面的函数是按照卷积的定义实现的四维卷积，包含以下循环：
1. 批量数据循环：bs in batch_size，对每个样本数据（图像）进行计算；
2. 输出通道循环：oc in output_channel。这里先把bias加上了，后加也可以；
3. 输入通道循环：ic in input_channel;
4. 输出图像纵坐标循环：i in out h；
5. 输出图像横坐标循环：j in out_w。循环4和5完成对输出图像的每个点的计算；
6. 卷积核纵向循环：fh in filter_height；
7. 卷积核横向循环：fw in filter_width。循环6和7完成卷积核每个点与输入图像每个点的卷积计算。

```Python
def conv_4d(x, weights, bias, out_h, out_w, stride=1):
    batch_size = x.shape[0]
    input_channel = x.shape[1]
    output_channel = weights.shape[0]
    filter_height = weights.shape[2]
    filter_width = weights.shape[3]
    rs = np.zeros((batch_size, num_output_channel, out_h, out_w))

    for bs in range(batch_size):
        for oc in range(output_channel):
            rs[bs,oc] += bias[oc]
            for ic in range(input_channel):
                for i in range(out_h):
                    for j in range(out_w):
                        ii = i * stride
                        jj = j * stride
                        for fh in range(filter_height):
                            for fw in range(filter_width):
                                rs[bs,oc,i,j] += x[bs,ic,fh+ii,fw+jj] * weights[oc,ic,fh,fw]
```

上面的代码完全按照前向计算公式来实现，我们试着运行10次，看看它的执行效率如何：
```Python
    s1 = time.time()
    for i in range(10):
        output1 = conv_4d(x, wb.W, wb.B, output_height, output_width, stride)
    e1 = time.time()
    print("Time used for Python:", e1 - s1)
```

和想象中完全不一样，足足等了30多秒后，才返回结果：

```
Time used for Python: 38.057225465774536
```

我们通过试验发现，其运行速度非常慢，如果这样的函数在神经网络训练中被调用几十万次，其性能是非常糟糕的，这也是Python做为动态语言的的一个缺点。

### 17.2.3 卷积运算的实现 - 方法2

既然动态语言速度慢，我们把它编译成静态方法，是不是会快一些呢？

很幸运，有这样一个开源项目：https://numba.pydata.org/，它可以在运行时把Python编译成C语言执行。代码可以完全是用C语言风格编写的，而且越像C的话，执行速度越快。

我们先用pip按照numba包：
```
pip install numba
```
然后在需要加速的函数前面加上一个装饰符：
```Python
@nb.jit(nopython=True)
def jit_conv_4d(x, weights, bias, out_h, out_w, stride=1):
    ...
```
为了明确起见，我们把conv_4d前面加上一个jit前缀，表明这个函数是经过numba加速的。然后运行下面的测试代码：

```Python
    # dry run
    output2 = jit_conv_4d(x, wb.W, wb.B, output_height, output_width, stride)
    s2 = time.time()
    for i in range(10):
        output2 = jit_conv_4d(x, wb.W, wb.B, output_height, output_width, stride)
    e2 = time.time()
    print("Time used for Numba:", e2 - s2)
```
运行结果：
```
Time used for Numba: 0.0727994441986084
```
不可想象的是，本次只用了0.07秒，比Python方法快了500多倍！

但是不要急，我们还需要检查一下其正确性：

```Python
    print("correctness:", np.allclose(output1, output2, atol=1e-7))
```
得到的结果是：
```
correctness: True
```
上面的代码检查两种方法的返回值的差异，如果绝对误差在1e-7之内，说明两个返回的四维数组完全相同，运算结果可信。

### 17.2.4 卷积层的实现 - 方法3

#### 原理

由于卷积操作是原始图片数据与卷积核逐点相乘的结果，所以运算速度非常慢。在Caffee框架中，巧妙地把逐点相乘的运算转换成了矩阵运算，大大提升了程序运行速度。这就是著名的im2col函数。

我们观察一下下面这张图：

<img src="../Images/17/img2col.png">

先看上半部分：绿色的3x3矩阵为输入，经过棕色的卷积核运算后，得到右侧的2x2的矩阵。

在全连接层中，由于是两个矩阵直接相乘，所以速度非常快。我们是否可以把卷积操作转换为矩阵操作呢？答案就在上图的下半部分：

第一步，上半部分中蓝色的虚线圆内的四个元素排列成第1行，形成[0,1,3,4]，红色虚线圆内的四个元素排列成第4行[4,5,7,8]，中间两行可以从右上角的[1,2,4,5]和左下角的[3,4,6,7]得到。这样，一个3x3的矩阵，就转换成了一个4x4的矩阵。

第二步，把棕色的权重矩阵变成4x1的矩阵，[3,2,1,0]。

第三步，把4x4的矩阵与4x1的矩阵相乘，得到4x1的结果矩阵[5,11,23,29]。

第四步：把4x1的结果矩阵变成2x2的矩阵，就是卷积运算的真实结果。

#### 四维数组的展开

前面只说明了二维数组的展开形式，四维数组可以用同样的方式展开。

我们假定有2个输入样本，每个样本含有3个通道，每个通道上是3x3的数据，则样本的原始形状和展开形状分别是：
```
x=
(样本1)
    (通道1)
 [[[[ 0  1  2]
   [ 3  4  5]
   [ 6  7  8]]
    (通道2)
  [[ 9 10 11]
   [12 13 14]
   [15 16 17]]
    (通道3)
  [[18 19 20]
   [21 22 23]
   [24 25 26]]]
[样本2]
    (通道1)
 [[[27 28 29]
   [30 31 32]
   [33 34 35]]
    (通道2)
  [[36 37 38]
   [39 40 41]
   [42 43 44]]
    (通道3)
  [[45 46 47]
   [48 49 50]
   [51 52 53]]]]
col=
 [[ 0.  1.  3.  4.  9. 10. 12. 13. 18. 19. 21. 22.]
 [ 1.  2.  4.  5. 10. 11. 13. 14. 19. 20. 22. 23.]
 [ 3.  4.  6.  7. 12. 13. 15. 16. 21. 22. 24. 25.]
 [ 4.  5.  7.  8. 13. 14. 16. 17. 22. 23. 25. 26.]
 [27. 28. 30. 31. 36. 37. 39. 40. 45. 46. 48. 49.]
 [28. 29. 31. 32. 37. 38. 40. 41. 46. 47. 49. 50.]
 [30. 31. 33. 34. 39. 40. 42. 43. 48. 49. 51. 52.]
 [31. 32. 34. 35. 40. 41. 43. 44. 49. 50. 52. 53.]]
```

从生成的4x12的矩阵中可以观察到：

- 前4行是样本1的数据，后4行是样本2的数据
- 前4列是通道1的数据，中间4列是通道2的数据，后4列是通道3的数据

#### 权重数组的展开

对应的四维输入数据，卷积核权重数组也需要是四维的，其原始形状和展开后的形状如下：
```
weights=
(过滤器1)
    (卷积核1)
 [[[[ 0  1]
   [ 2  3]]
    (卷积核2)
  [[ 4  5]
   [ 6  7]]
    (卷积核3)
  [[ 8  9]
   [10 11]]]
(过滤器2)
    (卷积核1)
 [[[12 13]
   [14 15]]
    (卷积核2)
  [[16 17]
   [18 19]]
    (卷积核3)
  [[20 21]
   [22 23]]]]
w=
 [[ 0 12]
  [ 1 13]
  [ 2 14]
  [ 3 15]
  [ 4 16]
  [ 5 17]
  [ 6 18]
  [ 7 19]
  [ 8 20]
  [ 9 21]
  [10 22]
  [11 23]]
```

#### 结果数据的处理

原始数据展开成了8x12的矩阵，权重展开成了12x2的矩阵，所以最后的结果是8x2的矩阵：
```
[[1035. 2619.]
 [1101. 2829.]
 [1233. 3249.]
 [1299. 3459.]
 [2817. 8289.]
 [2883. 8499.]
 [3015. 8919.]
 [3081. 9129.]]
```
注意这是两个样本的结果。如何把它拆开呢？是简单的左右分开就行了吗？这里要稍微动一下脑筋，推理一下：

1. 如果原始数据只有一个样本，则展开矩阵形状是4x12，那么结果将会是4x2。所以，在上面这个8x2的矩阵中，前4行应该是第一个样本的卷积结果，后4行是第二个样本的卷积结果。
2. 如果输出通道只有一个，则权重矩阵展开后只有一列，那么结果将会是8x1，目前的结果是8x2，所以第一列和第二列应该是两个通道的数据。

也就是说，在这个8x2的数组中：
- 第1列的前4行是第1个样本的第1个通道的输出
- 第2列的前4行是第1个样本的第2个通道的输出
- 第1列的后4行是第2个样本的第1个通道的输出
- 第2列的后4行是第2个样本的第2个通道的输出

于是我们可以分两步得到正确的矩阵形状：
1. 先把8x2的数据变成2个样本 x 输出高度 x 输出宽度的的形状：
```Python
out2 = output.reshape(batch_size, output_height, output_width, -1)
```
得到结果：
```
out2= 

[[[[1035. 2619.]
   [1101. 2829.]]

  [[1233. 3249.]
   [1299. 3459.]]]


 [[[2817. 8289.]
   [2883. 8499.]]

  [[3015. 8919.]
   [3081. 9129.]]]]
```
注意现在1035和2619在一个子矩阵中，这是不对的，因为它们应该属于两个通道，所以应该在两个子矩阵中，于是我们做第二步：

2. 把第4维数据放到第2维：

```Python
out3 = np.transpose(out2, axes=(0, 3, 1, 2))
```
结果是：
```
conv result=
(样本1)
    (通道1)
 [[[[1035. 1101.]
   [1233. 1299.]]
    (通道2)
  [[2619. 2829.]
   [3249. 3459.]]]

(样本2)
    (通道1)
 [[[2817. 2883.]
   [3015. 3081.]]
    (通道2)
  [[8289. 8499.]
   [8919. 9129.]]]]
```

#### 验证正确性

我们可以用Python实现的方法做为基准，如果用矩阵法可以得到同样的结果，就说明这种方式是正确的。

```Python
def test_4d_im2col():
    batch_size = 2
    stride = 1
    padding = 0
    fh = 2
    fw = 2
    input_channel = 3
    output_channel = 2
    iw = 3
    ih = 3

    x = np.random.randn(batch_size, input_channel, iw, ih)
    params = HyperParameters_4_2(
        0.1, 1, batch_size,
        net_type=NetType.MultipleClassifier,
        init_method=InitialMethod.Xavier)
    c1 = ConvLayer((input_channel,iw,ih), (output_channel,fh,fw), (stride, padding), params)
    c1.initialize("test", "test", False)
    f1 = c1.forward_numba(x)
    f2 = c1.forward_img2col(x)
    print("correctness:", np.allclose(f1, f2, atol=1e-7))
```

上面的代码，首先生成了一个ConvLayer实例，然后分别调用内部实现的forward_numba()方法和forward_img2col()方法，得到f1和f2两个矩阵，然后比较其结果，最后的返回值为True，说明im2col方法的正确性。

#### 比较性能

下面我们比较一下方法2和方法3的性能，然后决定我们使用那种方法。

```Python
def test_performance():
    ...
    # 64 个 3 x 28 x 28 的图像输入（模拟 mnist）
    x = np.random.randn(batch_size, input_channel, iw, ih)
    
    c1 = ConvLayer((input_channel,iw,ih), (output_channel,fh,fw), (stride, padding), params)
    c1.initialize("test", "test", False)

    s1 = time.time()
    for i in range(1000):
        f1 = c1.forward_numba(x)
    e1 = time.time()
    print("method numba:", e1-s1)

    s2 = time.time()
    for i in range(1000):
        f2 = c1.forward_img2col(x)
    e2 = time.time()
    print("method im2col:", e2-s2)
    
    print("compare correctness of method 1 and method 2:")
    print("forward:", np.allclose(f1, f2, atol=1e-7))
```

上述代码先生成一个ConvLayer实例，然后分别调用1000次forward_numba()方法和1000次forward_img2col()方法，最后得到的结果是：

```
method numba: 11.663846492767334
method im2col: 14.926148653030396
compare correctness of method 1 and method 2:
forward: True
```

numba方法会比im2col方法快3秒。

### 代码位置

ch17, Level1, Level2

其中，Level1是测试numba库的性能，Level2是比较numba方法和im2col方法的前向计算性能。

在Level2的主过程中有4个函数：
- test_2d_conv，理解2维下im2col的工作原理
- understand_4d_im2col，理解4维下im2col的工作原理
- test_4d_im2col，比较两种方法的结果，从而验证正确性
- test_performance，比较两种方法的性能
